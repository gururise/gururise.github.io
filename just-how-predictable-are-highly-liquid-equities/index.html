
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Predictability of liquid equities</title>
    <meta name="description" content="">

    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="shortcut icon" href="../assets/favicon.ico">

    <link rel="stylesheet" type="text/css" href="../assets/css/screen.css?v=23c853b158">
    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400">

    <link rel="canonical" href="https://gururise.github.io/just-how-predictable-are-highly-liquid-equities/">
    <meta name="referrer" content="origin">
    
    <meta property="og:site_name" content="Random Synaptic Firings">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Predictability of liquid equities">
    <meta property="og:description" content="Autocorrelation (somtimes referred to as lagged-correlation) is defined as the linear dependence of a variable with itself at two points in time.  Define:  $Cov(y_t,y_{t-h}) = y_h$ Lag-h autocorrelation is given by: $\rho_h = Corr(y_t,y_{t-h}) = \frac{y_h}{y_0}$ The denominator $y_">
    <meta property="og:url" content="https://gururise.github.io/just-how-predictable-are-highly-liquid-equities/">
    <meta property="article:published_time" content="2015-04-05T02:09:00.000Z">
    <meta property="article:modified_time" content="2016-05-18T06:05:42.829Z">
    <meta property="article:tag" content="machine learning">
    <meta property="article:tag" content="time-series prediction">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Predictability of liquid equities">
    <meta name="twitter:description" content="Autocorrelation (somtimes referred to as lagged-correlation) is defined as the linear dependence of a variable with itself at two points in time.  Define:  $Cov(y_t,y_{t-h}) = y_h$ Lag-h autocorrelation is given by: $\rho_h = Corr(y_t,y_{t-h}) = \frac{y_h}{y_0}$ The denominator $y_">
    <meta name="twitter:url" content="https://gururise.github.io/just-how-predictable-are-highly-liquid-equities/">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Gene Ruebsamen">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="machine learning, time-series prediction">
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Random Synaptic Firings",
    "author": {
        "@type": "Person",
        "name": "Gene Ruebsamen",
        "url": "https://gururise.github.io/author/gene/"
    },
    "headline": "Predictability of liquid equities",
    "url": "https://gururise.github.io/just-how-predictable-are-highly-liquid-equities/",
    "datePublished": "2015-04-05T02:09:00.000Z",
    "dateModified": "2016-05-18T06:05:42.829Z",
    "keywords": "machine learning, time-series prediction",
    "description": "Autocorrelation (somtimes referred to as lagged-correlation) is defined as the linear dependence of a variable with itself at two points in time.  Define:  $Cov(y_t,y_{t-h}) &#x3D; y_h$ Lag-h autocorrelation is given by: $\\rho_h &#x3D; Corr(y_t,y_{t-h}) &#x3D; \\frac{y_h}{y_0}$ The denominator $y_"
}
    </script>

    <meta name="generator" content="Ghost 0.7">
    <link rel="alternate" type="application/rss+xml" title="Random Synaptic Firings" href="https://gururise.github.io/rss/">
</head>
<body class="post-template tag-machine-learning tag-time-series-prediction nav-closed">

    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="index.html#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
            <li class="nav-home" role="presentation"><a href="https://gururise.github.io/">Home</a></li>
    </ul>
    <a class="subscribe-button icon-feed" href="https://gururise.github.io/rss/">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        


<header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        
            <a class="menu-button icon-menu" href="index.html#"><span class="word">Menu</span></a>
    </nav>
</header>

<main class="content" role="main">
    <article class="post tag-machine-learning tag-time-series-prediction">

        <header class="post-header">
            <h1 class="post-title">Predictability of liquid equities</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2015-04-04">04 April 2015</time>  on <a href="../tag/machine-learning/">machine learning</a>, <a href="../tag/time-series-prediction/">time-series prediction</a>
            </section>
        </header>

        <section class="post-content">
            <p><a href="https://en.wikipedia.org/wiki/Autocorrelation">Autocorrelation</a> (somtimes referred to as lagged-correlation) is defined as the linear dependence of a variable with itself at two points in time. <br>
Define: <br>
$$Cov(y_t,y_{t-h}) = y_h$$
Lag-h autocorrelation is given by:</p>

<p>$$\rho_h = Corr(y_t,y_{t-h}) = \frac{y_h}{y_0}$$
The denominator $y_0$ is the lag 0 covariance.</p>

<p>Knowing this, we can calculate the autocorrelation of a signal and it will tell us the similarity betweens observations as a function of time lag between the observations.  One would expect a signal with a high autocorrelation to be more predictable than one with a low autocorrelation.  What does the autocorrelation of various equities look like?  We are about to find out.</p>

<h3 id="howpredictableisnoise">How predictable is noise?</h3>

<p>First we should take a look at the correlation of a random signal.  Lets introduce some gaussian noise.</p>

<pre><code class="language-python">noise=np.random.normal(0,1,201)/3  #mean, std dev, num pts  
plot_acorr(noise,"noise") # autocorrelation plotting function  
</code></pre>

<p><img src="../content/images/2016/05/output_4_0-1.png" alt="png"></p>

<p>As expected, there is very little correlation at any lag (n != 0) in random noise.  This indicates there are no underlying patterns in the signal and is what we would expect to see in this case.</p>

<h3 id="howmuchcorrelationdoesasinewavehave">How much correlation does a sine wave have?</h3>

<p>A sine wave is a good start. Being derived from the unit circle, it's a repeating signal that is highly predictable.  Lets take a look the autocorrelation of a highly predictable signal.</p>

<pre><code class="language-python">x = np.sin(np.linspace(-np.pi, np.pi, 201))  
plot_acorr(x,"sin(x)")  
</code></pre>

<p><img src="../content/images/2016/05/output_6_0-1.png" alt="png"></p>

<p>Very high autocorrelation in a clean sine signal.  But the real world is not that nice.  A clean signal is not a realistic model of an equity. How about we add some gaussian noise to the signal and look at the autocorrelation again.</p>

<pre><code class="language-python">noise=np.random.normal(0,1,201)/3  #mean, std dev, num pts  
sig=x+noise  
plot_acorr(sig,"noisy sin(x)")  
</code></pre>

<p><img src="../content/images/2016/05/output_8_0-1.png" alt="png"></p>

<p>Even with gaussian noise added to the original signal, the autocorrelation is still quite high. There are quite a few regression methods we could use that could predict/extract the original signal from the noise in the above example. But does our noisy sine signal model real world equities? Are there really patterns hidden in the noise in equity markets? <br>
We now look at a real signal from the equities market to see how autocorrelated those signals are.</p>

<pre><code class="language-python">plot_acorr(ibm_df['Adj Close'],"IBM")  
</code></pre>

<p><img src="../content/images/2016/05/output_10_0-1.png" alt="png"></p>

<h3 id="isthisthemagicbullet">Is this the magic bullet?</h3>

<p>Is this real?  Did I just show a highly liquid equity with a detectable pattern in the price signal?  Obviously not. Looking at the price is a mistake and knowing the price doesn't change much on a day to day basis won't help us. If it were this easy, I would imagine there would be many rich high school kids.  So what's the problem?</p>

<h3 id="whatinformationdoweneed">What information do we need?</h3>

<p>Since we want to predict the daily change in equity price we need to look at the correlation in percent change rather than the raw price. Lets do that:</p>

<pre><code class="language-python">plot_acorr(ibm_df['Adj Close'].pct_change().values[1:],"IBM % Change")  
</code></pre>

<p><img src="../content/images/2016/05/output_12_0.png" alt="png"></p>

<h3 id="sorryitsnotgoingtobethateasy">Sorry, it's not going to be that easy...</h3>

<p>What a difference!  The plot now looks very similar to the random noise plot above. There is almost no correlation at any time lag. This tends to indicate there is little predictability in equities using price alone.  This has been my experience when using signals derived from equity price. So the next time someone tells you they fed stock market data into a neural network and are able to predict tomorrow's price, show them this blog post!</p>

<p>Is this the end for predicting time-series derived from equities? Not at all, but things are going to get <strong>a lot more complicated</strong>... stay tuned.</p>
        </section>

        <footer class="post-footer">



            <section class="author">
                <h4><a href="../author/gene/">Gene Ruebsamen</a></h4>

                    <p>Read <a href="../author/gene/">more posts</a> by this author.</p>
                <div class="author-meta">
                    
                    
                </div>
            </section>


            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="https://twitter.com/intent/tweet?text=Predictability%20of%20liquid%20equities&amp;url=https://gururise.github.io/just-how-predictable-are-highly-liquid-equities/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://gururise.github.io/just-how-predictable-are-highly-liquid-equities/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=https://gururise.github.io/just-how-predictable-are-highly-liquid-equities/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>

        </footer>

    </article>
</main>

<aside class="read-next">
    <a class="read-next-story no-cover" href="../levitation/">
        <section class="post">
            <h2>Electromagnetic Levitation</h2>
            <p>The Idea My 10yr old son asked, a few weeks ago, how he could build a mag-lev train for…</p>
        </section>
    </a>
    <a class="read-next-story prev no-cover" href="../machine-learning-on-an-8-bit-micro/">
        <section class="post">
            <h2>Machine Learning on an 8-bit Micro</h2>
            <p>8 bits, but 16Mhz! I recently built a robot that utilized a Atmel ATmega328P 8-bit processor.  Sensory input consisted…</p>
        </section>
    </a>
</aside>



        <footer class="site-footer clearfix">
            <section class="copyright"><a href="https://gururise.github.io">Random Synaptic Firings</a> © 2016</section>
            <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
        </footer>

    </div>

    <script type="text/javascript" src="https://code.jquery.com/jquery-1.12.0.min.js"></script>
    

    <script type="text/javascript" src="../assets/js/jquery.fitvids.js?v=23c853b158"></script>
    <script type="text/javascript" src="../assets/js/index.js?v=23c853b158"></script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/x-mathjax-config">  
MathJax.Hub.Config({  
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>  
</body>
